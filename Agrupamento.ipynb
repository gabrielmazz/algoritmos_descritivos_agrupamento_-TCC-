{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as mt\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.table import Table \n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataframe.cores import *\n",
        "# Declara a classe cores\n",
        "cores = cores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Resposta.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Função de Otimização do KMeans\n",
        "\n",
        "Define uma função ideal para o kmeans que executa clustering K-means em um determinado DataFrame df para um intervalo de números de cluster e visualiza os resultados. A função leva três argumentos: df (o DataFrame a ser agrupado), start (o número inicial de clusters a testar) e end (o número final de clusters a testar). Resultando em todos os possiveis valores de clusters e suas respectivas inércias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esta função plota a soma dos erros quadráticos (SSE) e o escore de silhueta para um intervalo de clusters.\n",
        "def optimal_kmeans(df, start=2, end=11):\n",
        "    \n",
        "    '''\n",
        "    df: DataFrame que sera clusterizado.\n",
        "    start: Número inicial de clusters que você deseja testar.\n",
        "    end: Número final de clusters que você deseja testar.\n",
        "    '''\n",
        "    \n",
        "    # Soma dos erros quadráticos\n",
        "    sse = {}\n",
        "    \n",
        "    # Escore de silhueta\n",
        "    silhouette = {}\n",
        "    \n",
        "    # Adiciona um dicionario de resultados\n",
        "    results = {}\n",
        "    \n",
        "    for k in range(start, end):\n",
        "        kmeans = KMeans(n_clusters=k, max_iter=100, random_state=42).fit(df)\n",
        "        df[\"clusters\"] = kmeans.labels_\n",
        "        sse[k] = kmeans.inertia_ \n",
        "        silhouette[k] = silhouette_score(df, kmeans.labels_, metric='euclidean')\n",
        "      \n",
        "\n",
        "    # Plota um subplot com o plotly com o primeiro gráfico sendo o sse e o outro com o silouette\n",
        "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"SSE\", \"Silhouette Score\"))\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=list(sse.keys()), y=list(sse.values()), \n",
        "                             name='SSE'), row=1, col=1)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(x=list(silhouette.keys()), y=list(silhouette.values()), \n",
        "                             name='Silhouette Score'), row=1, col=2)\n",
        "    \n",
        "    fig.update_layout(title_text=\"Gráfico de análise - SSE e Silhouette Score\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        autosize=False,\n",
        "        width=1800,\n",
        "        height=800,\n",
        "    )    \n",
        "\n",
        "    fig.show()\n",
        "    \n",
        "    # Com o rich, cria uma tabela com os resultados\n",
        "    table = Table(title=\"Resultados\")\n",
        "    table.add_column(\"Clusters\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
        "    table.add_column(\"SSE\", justify=\"center\", style=\"magenta\", no_wrap=True)\n",
        "    table.add_column(\"Silhouette Score\", justify=\"center\", style=\"green\", no_wrap=True)\n",
        "    \n",
        "    for k in range(start, end):\n",
        "        table.add_row(str(k), str(sse[k]), str(silhouette[k]))\n",
        "\n",
        "    console = Console()\n",
        "    console.print(table)\n",
        "\n",
        "# Uso da função\n",
        "optimal_kmeans(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Função de Otimização do DBSCAN\n",
        "\n",
        "Define uma função ideal para o dbscan que é usada para encontrar os parâmetros ideais para o algoritmo de cluster DBSCAN (Density-Based Spatial Clustering of Applications with Noise). A função leva um DataFrame df para ser agrupado, um intervalo de eps_values (distância máxima entre duas amostras para que elas sejam consideradas na mesma vizinhança) e min_samples_values (o número de amostras em uma vizinhança para que um ponto seja considerado como um ponto central) como entradas. Realizando uma busca em grade, mostrando todos os valores possiveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esta função plota o escore de silhueta para uma variedade de valores eps e min_samples.\n",
        "def optimal_dbscan(df, eps_values=np.linspace(0.1, 20, 50), min_samples_values=range(2, 15)):\n",
        "    \n",
        "    '''\n",
        "    df: DataFrame que sera clusterizado.\n",
        "    eps_values: Valores de eps que você deseja testar.\n",
        "    min_samples_values: Valores de min_samples que você deseja testar.\n",
        "    '''\n",
        "    \n",
        "    # Escore de silhueta\n",
        "    silhouette = {}\n",
        "    \n",
        "    for eps in eps_values:\n",
        "        for min_samples in min_samples_values:\n",
        "            dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(df)\n",
        "            n_clusters = len(set(dbscan.labels_))\n",
        "            if 1 < n_clusters < df.shape[0]:  # Deve haver pelo menos 2 clusters e menos que n_samples para o escore de silhueta\n",
        "                silhouette[(eps, min_samples)] = silhouette_score(df, dbscan.labels_)\n",
        "    \n",
        "    # Plota um gráfico com o plotly\n",
        "    fig = go.Figure(data=go.Scatter(x=[str(i) for i in silhouette.keys()], y=list(silhouette.values())))\n",
        "    \n",
        "    fig.update_layout(title_text=\"Gráfico de análise - DBSCAN\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        autosize=False,\n",
        "        width=1400,\n",
        "        height=1000,\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Com o rich, cria uma tabela com os resultados\n",
        "    table = Table(title=\"Resultados\")\n",
        "    table.add_column(\"Eps\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
        "    table.add_column(\"Min Samples\", justify=\"center\", style=\"magenta\", no_wrap=True)\n",
        "    table.add_column(\"Silhouette Score\", justify=\"center\", style=\"green\", no_wrap=True)\n",
        "    \n",
        "    for key, value in silhouette.items():\n",
        "        table.add_row(str(key[0]), str(key[1]), str(value))\n",
        "    \n",
        "    console = Console()\n",
        "    console.print(table)\n",
        "    \n",
        "optimal_dbscan(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Função de Otimização do AGNES\n",
        "\n",
        "Define a função que é usada para encontrar o número ideal de clusters e método de ligação para Agglomerative Clustering (AGNES) em um determinado conjunto de dados. AGNES é um tipo de método de agrupamento hierárquico que mescla o par mais próximo de clusters em cada etapa. Resultando em todos os possiveis valores de clusters e suas respectivas inércias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimal_agnes(df, start=2, end=11, linkage_methods=['ward', 'complete', 'average', 'single']):\n",
        "    '''\n",
        "    Esta função plota o escore de silhueta para um intervalo de números de clusters e métodos de ligação.\n",
        "    df: DataFrame. Seus dados.\n",
        "    start: int. Número inicial de clusters que você deseja testar.\n",
        "    end: int. Número final de clusters que você deseja testar.\n",
        "    linkage_methods: list. Métodos de ligação que você deseja testar.\n",
        "    '''\n",
        "    \n",
        "    # Escore de silhueta\n",
        "    silhouette = {}\n",
        "    \n",
        "    for linkage in linkage_methods:\n",
        "        for n_clusters in range(start, end):\n",
        "            agnes = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage).fit(df)\n",
        "            labels = agnes.labels_\n",
        "            silhouette[(linkage, n_clusters)] = silhouette_score(df, labels, metric='euclidean')\n",
        "    \n",
        "    # Plota um gráfico com o plotly com todos os métodos de ligação na mesma figura\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for linkage in linkage_methods:\n",
        "        fig.add_trace(go.Scatter(x=list(range(start, end)), y=[silhouette[(linkage, i)] for i in range(start, end)], \n",
        "                         mode='lines+markers', name=linkage))\n",
        "        \n",
        "    fig.update_layout(title_text=\"Gráfico de análise - Agglomerative Clustering\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        autosize=False,\n",
        "        width=1400,\n",
        "        height=800,\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    # Com o rich, cria uma tabela com os resultados\n",
        "    table = Table(title=\"Resultados\")\n",
        "    table.add_column(\"Linkage\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
        "    table.add_column(\"Clusters\", justify=\"center\", style=\"magenta\", no_wrap=True)\n",
        "    table.add_column(\"Silhouette Score\", justify=\"center\", style=\"green\", no_wrap=True)\n",
        "    \n",
        "    for key, value in silhouette.items():\n",
        "        table.add_row(str(key[0]), str(key[1]), str(value))\n",
        "        \n",
        "    console = Console()\n",
        "    console.print(table)\n",
        "\n",
        "# Uso da função\n",
        "optimal_agnes(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Técnicas utilizadas para redução de dimensionalidade\n",
        "\n",
        "## PCA (Principal Component Analysis)\n",
        "\n",
        "PCA, ou Análise de Componentes Principais, é uma técnica de redução de dimensionalidade usada em aprendizado de máquina e estatística. O objetivo do PCA é transformar um conjunto de variáveis possivelmente correlacionadas em um conjunto menor de variáveis não correlacionadas chamadas componentes principais.\n",
        "\n",
        "### No código\n",
        "\n",
        "```python\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "```\n",
        "- n_components: número de componentes principais a serem mantidos, aqui, um objeto PCA é criado, especificando que queremos reduzir nosso conjunto de dados para 2 componentes principais\n",
        "\n",
        "```python\n",
        "principalComponents = pca.fit_transform(df)\n",
        "```\n",
        "\n",
        "- O método fit_transform() é chamado no objeto PCA, que calcula os componentes principais do DataFrame df e usa esses componentes para transformar df em um novo espaço de dados. O resultado é um array numpy principalComponents que contém os dados transformados\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Método do KMeans\n",
        "\n",
        "O KMeans é um método de clusterização que tem como objetivo dividir um conjunto de dados em K grupos, onde K é um número pré-definido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a função para o KMeans\n",
        "def KMeans_Trainer(df):\n",
        "    \n",
        "    # Determina o número de clusters do K-Means\n",
        "    n_clusters = 5\n",
        "\n",
        "    # Determina o máximo de iteração\n",
        "    max_iter = 100\n",
        "    \n",
        "    # Define o modelo\n",
        "    model = KMeans(n_clusters=n_clusters, max_iter=max_iter, random_state=42)    \n",
        "    \n",
        "    # Define os dados de treino\n",
        "    model.fit(df)\n",
        "    \n",
        "    # Define a opinião do modelo\n",
        "    X = model.labels_\n",
        "\n",
        "    # Printa a opinião do modelo com o rich\n",
        "    console = Console()\n",
        "    table = Table(title=\"Opinião do Modelo K-Means\")\n",
        "    table.add_column(\"Cluster\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Opinião\", style=\"magenta\", justify=\"center\")\n",
        "    for i in range(n_clusters):\n",
        "        table.add_row(str(i), str(np.sum(X == i)))\n",
        "    console.print(table)\n",
        "    \n",
        "    # Printa o X com o rich\n",
        "    console = Console()\n",
        "    console.print(X)\n",
        "    \n",
        "    # Plota o gráfico de dispersão dos dados K-Means\n",
        "    \n",
        "    # Supondo que meu dataframe seja o 'X' e que 'y_kmeans' seja o resultado do agrupamento\n",
        "    pca = PCA(n_components=2)\n",
        "    principalComponents = pca.fit_transform(df)\n",
        "\n",
        "    # Cria um dataframe com os componentes principais\n",
        "    principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "\n",
        "    # Adiciona a coluna de agrupamento\n",
        "    principalDf['cluster'] = X\n",
        "\n",
        "    # Ordena o DataFrame pelo valor do cluster (Arruma a legenda do gráfico para que os clusters fiquem em ordem crescente)\n",
        "    principalDf = principalDf.sort_values(by='cluster')\n",
        "\n",
        "    # Transforma na df todos o cluster, os que era 0 viram 1, 1 vira 2 e assim por diante\n",
        "    principalDf['cluster'] = principalDf['cluster'] + 1\n",
        "\n",
        "    # Plota o gráfico de dispersão\n",
        "    fig = px.scatter(principalDf, x='principal component 1', y='principal component 2', symbol='cluster', size='cluster', color='cluster')\n",
        "\n",
        "    # Atualiza o layout do gráfico\n",
        "    fig.update_layout(\n",
        "        width=800, \n",
        "        height=800)\n",
        "\n",
        "    # Atualiza o X e Y do gráfico retirando-os\n",
        "    fig.update_xaxes(title_text='')\n",
        "    fig.update_yaxes(title_text='')\n",
        "    \n",
        "    # Remove a barra de cores\n",
        "    fig.update_layout(coloraxis_showscale=False)\n",
        "    \n",
        "    # Retira o fundo do gráfico (grid) colocando-o branco\n",
        "    fig.update_layout(plot_bgcolor='white')\n",
        "    \n",
        "    # Retira o axis do gráfico\n",
        "    fig.update_xaxes(showline=False, showgrid=False, zeroline=False)\n",
        "    fig.update_yaxes(showline=False, showgrid=False, zeroline=False)\n",
        "    \n",
        "    # Retira os numeros do eixo X e Y\n",
        "    fig.update_xaxes(showticklabels=False)\n",
        "    fig.update_yaxes(showticklabels=False)\n",
        "    \n",
        "    # Organiza a legenda em ordem crescente de clusters\n",
        "    fig.for_each_trace(lambda t: t.update(name='Cluster ' + str(t.name)))\n",
        "\n",
        "    # Configura a legenda\n",
        "    fig.update_layout(\n",
        "        legend=dict(\n",
        "            traceorder='normal',\n",
        "            font=dict(\n",
        "                family='sans-serif',\n",
        "                size=20,\n",
        "                color='black'\n",
        "            ),\n",
        "            bordercolor='Black',\n",
        "            borderwidth=2\n",
        "        ),\n",
        "        \n",
        "        # Padding para tirar o espaço em branco em volta do gráfico\n",
        "        margin=dict(l=0, r=0, t=0, b=0)\n",
        "    )\n",
        "    \n",
        "    # Retira o titulo da legenda\n",
        "    fig.update_layout(legend_title_text='')\n",
        "\n",
        "    # Exibe o gráfico\n",
        "    fig.show()\n",
        "    \n",
        "    # Soma dos quadrados das distâncias\n",
        "    sse = model.inertia_\n",
        "    \n",
        "    # Calcula a coesao\n",
        "    cohesion = mt.sqrt(model.inertia_)/model.n_clusters\n",
        "    \n",
        "    # Calcula o coeficiente de silhueta\n",
        "    silhouette_kmeans = silhouette_score(df, X)\n",
        "    \n",
        "    # Rand score do KMeans\n",
        "    rand_kmeans = metrics.adjusted_rand_score(df['clusters'], X)\n",
        "    \n",
        "    # Homogeneidade\n",
        "    homogeneity = metrics.homogeneity_score(df['clusters'], X)\n",
        "    \n",
        "    # Completude\n",
        "    completeness = metrics.completeness_score(df['clusters'], X)\n",
        "    \n",
        "    # Matriz de confusão\n",
        "    confusion_matrix = metrics.cluster.contingency_matrix(df['clusters'], X)\n",
        "    \n",
        "    \n",
        "    # Printa \n",
        "    console = Console()\n",
        "    table = Table(title=\"Resultados do K-Means\")\n",
        "    table.add_column(\"SSE\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Coesão\", style=\"magenta\", justify=\"center\")\n",
        "    table.add_column(\"Silhouette Score\", style=\"green\", justify=\"center\")\n",
        "    table.add_column(\"Homogeneidade\", style=\"blue\", justify=\"center\")\n",
        "    table.add_column(\"Rand Score\", style=\"yellow\", justify=\"center\")\n",
        "    table.add_column(\"Completude\", style=\"red\", justify=\"center\")\n",
        "    \n",
        "    \n",
        "    table.add_row(str(sse), str(cohesion), str(silhouette_kmeans), str(homogeneity), str(rand_kmeans), str(completeness))\n",
        "    \n",
        "    console.print(table)\n",
        "\n",
        "    # Printa a matriz de confusão\n",
        "    print(\"Matriz de Confusão\")\n",
        "    print(confusion_matrix)\n",
        "    \n",
        "    \n",
        "    return silhouette_kmeans\n",
        "    \n",
        "# Chamada da função KMeans\n",
        "silhouette_kmeans = KMeans_Trainer(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Método do DBSCAN\n",
        "\n",
        "O DBSCAN é um método de clusterização que tem como objetivo dividir um conjunto de dados em grupos de densidade, onde os grupos são formados por pontos que estão próximos uns dos outros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def DBSCAN_Trainer(df):\n",
        "    \n",
        "    # Define o EPS\n",
        "    eps = 7\n",
        "    \n",
        "    # Define o número mínimo de amostras\n",
        "    min_samples = 5\n",
        "    \n",
        "    # Define o modelo\n",
        "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    \n",
        "    # Define os dados de treino\n",
        "    model.fit(df)\n",
        "    \n",
        "    # Define a opinião do modelo\n",
        "    X = model.labels_\n",
        "\n",
        "    # Printa a opinião do modelo com o rich\n",
        "    console = Console()\n",
        "    table = Table(title=\"Opinião do Modelo DBSCAN\")\n",
        "    table.add_column(\"Cluster\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Opinião\", style=\"magenta\", justify=\"center\")\n",
        "    for i in range(len(np.unique(X))):\n",
        "        table.add_row(str(i), str(np.sum(X == i)))\n",
        "    console.print(table)\n",
        "    \n",
        "    # Printa o X com o rich\n",
        "    console = Console()\n",
        "    console.print(X)\n",
        "    \n",
        "    # Plota o gráfico de dispersão dos dados DBSCAN\n",
        "    \n",
        "    # Supondo que meu dataframe seja o 'X' e que 'y_kmeans' seja o resultado do agrupamento\n",
        "    pca = PCA(n_components=2)\n",
        "    principalComponents = pca.fit_transform(df)\n",
        "\n",
        "    # Cria um dataframe com os componentes principais\n",
        "    principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "\n",
        "    # Adiciona a coluna de agrupamento\n",
        "    principalDf['cluster'] = X\n",
        "\n",
        "    # Ordena o DataFrame pelo valor do cluster (Arruma a legenda do gráfico para que os clusters fiquem em ordem crescente)\n",
        "    principalDf = principalDf.sort_values(by='cluster')\n",
        "\n",
        "    # Transforma na df todos o cluster, os que era 0 viram 1, 1 vira 2 e assim por diante\n",
        "    principalDf['cluster'] = principalDf['cluster'] + 1\n",
        "\n",
        "    \n",
        "    # Plota o gráfico de dispersão\n",
        "    fig = px.scatter(principalDf, x='principal component 1', y='principal component 2', symbol='cluster', size='cluster', color='cluster')\n",
        "\n",
        "    # Atualiza o layout do gráfico\n",
        "    fig.update_layout(\n",
        "        width=800, \n",
        "        height=800)\n",
        "    \n",
        "    # Atualiza o X e Y do gráfico retirando-os\n",
        "    fig.update_xaxes(title_text='')\n",
        "    fig.update_yaxes(title_text='')\n",
        "    \n",
        "    # Remove a barra de cores\n",
        "    fig.update_layout(coloraxis_showscale=False)\n",
        "    \n",
        "    # Retira o fundo do gráfico (grid) colocando-o branco\n",
        "    fig.update_layout(plot_bgcolor='white')\n",
        "\n",
        "    # Retira o axis do gráfico\n",
        "    fig.update_xaxes(showline=False, showgrid=False, zeroline=False)\n",
        "    fig.update_yaxes(showline=False, showgrid=False, zeroline=False)\n",
        "    \n",
        "    # Retira os numeros do eixo X e Y\n",
        "    fig.update_xaxes(showticklabels=False)\n",
        "    fig.update_yaxes(showticklabels=False)\n",
        "    \n",
        "    # Organiza a legenda em ordem crescente de clusters\n",
        "    fig.for_each_trace(lambda t: t.update(name='Cluster ' + str(t.name)))\n",
        "    \n",
        "    # Configura a legenda\n",
        "    fig.update_layout(\n",
        "        legend=dict(\n",
        "            traceorder='normal',\n",
        "            font=dict(\n",
        "                family='sans-serif',\n",
        "                size=20,\n",
        "                color='black'\n",
        "            ),\n",
        "            bordercolor='Black',\n",
        "            borderwidth=2\n",
        "        ),\n",
        "        \n",
        "        # Padding para tirar o espaço em branco em volta do gráfico\n",
        "        margin=dict(l=0, r=0, t=0, b=0)\n",
        "    )\n",
        "    \n",
        "    # Retira o titulo da legenda\n",
        "    fig.update_layout(legend_title_text='')\n",
        "    \n",
        "    # Exibe o gráfico\n",
        "    fig.show()\n",
        "    \n",
        "    # Calcula o coeficiente de silhueta\n",
        "    n_clusters = len(set(X))\n",
        "    \n",
        "    if n_clusters > 1:\n",
        "        silhouette_dbscan = silhouette_score(df, X)\n",
        "    else:\n",
        "        silhouette_dbscan = 0\n",
        "    \n",
        "    \n",
        "    # Rand score do DBSCAN\n",
        "    rand_dbscan = metrics.adjusted_rand_score(df['clusters'], X)\n",
        "    \n",
        "    # Homogeneidade\n",
        "    homogeneity = metrics.homogeneity_score(df['clusters'], X)\n",
        "    \n",
        "    # Completude\n",
        "    completeness = metrics.completeness_score(df['clusters'], X)\n",
        "    \n",
        "    # Matriz de confusão\n",
        "    confusion_matrix = metrics.cluster.contingency_matrix(df['clusters'], X)\n",
        "    \n",
        "    # Printa\n",
        "    console = Console()\n",
        "    table = Table(title=\"Resultados do DBSCAN\")\n",
        "    table.add_column(\"Silhouette Score\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Rand Score\", style=\"magenta\", justify=\"center\")\n",
        "    table.add_column(\"Homogeneidade\", style=\"green\", justify=\"center\")\n",
        "    table.add_column(\"Completude\", style=\"yellow\", justify=\"center\")\n",
        "    \n",
        "    table.add_row(str(silhouette_dbscan), str(rand_dbscan), str(homogeneity), str(completeness))\n",
        "    \n",
        "    console.print(table)\n",
        "    \n",
        "    # Printa a matriz de confusão\n",
        "    print(\"Matriz de Confusão\")\n",
        "    print(confusion_matrix)\n",
        "    \n",
        "    return silhouette_dbscan\n",
        "\n",
        "# Chamada da função DBSCAN\n",
        "silhouette_dbscan = DBSCAN_Trainer(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Método do AGNES\n",
        "\n",
        "O AGNES é um método de clusterização que tem como objetivo dividir um conjunto de dados em grupos de hierarquia, onde os grupos são formados por pontos que estão próximos uns dos outros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def AGNES_Trainer(df):\n",
        "    \n",
        "    # Define o número de clusters\n",
        "    n_clusters = 5\n",
        "    \n",
        "    # Define o método de ligação\n",
        "    linkage = 'average'\n",
        "    \n",
        "    # Define o modelo\n",
        "    model = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
        "    \n",
        "    # Define os dados de treino\n",
        "    model.fit(df)\n",
        "    \n",
        "    # Define a opinião do modelo\n",
        "    X = model.labels_\n",
        "\n",
        "    # Printa a opinião do modelo com o rich\n",
        "    console = Console()\n",
        "    table = Table(title=\"Opinião do Modelo AGNES\")\n",
        "    table.add_column(\"Cluster\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Opinião\", style=\"magenta\", justify=\"center\")\n",
        "    for i in range(n_clusters):\n",
        "        table.add_row(str(i), str(np.sum(X == i)))\n",
        "    console.print(table)\n",
        "    \n",
        "    # Printa o X com o rich\n",
        "    console = Console()\n",
        "    console.print(X)\n",
        "    \n",
        "    # Plota o gráfico de dispersão dos dados AGNES\n",
        "    \n",
        "    # Supondo que meu dataframe seja o 'X' e que 'y_kmeans' seja o resultado do agrupamento\n",
        "    pca = PCA(n_components=2)\n",
        "    principalComponents = pca.fit_transform(df)\n",
        "\n",
        "    # Cria um dataframe com os componentes principais\n",
        "    principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "\n",
        "    # Adiciona a coluna de agrupamento\n",
        "    principalDf['cluster'] = X\n",
        "\n",
        "    # Ordena o DataFrame pelo valor do cluster (Arruma a legenda do gráfico para que os clusters fiquem em ordem crescente)\n",
        "    principalDf = principalDf.sort_values(by='cluster')\n",
        "    \n",
        "    # Transforma na df todos o cluster, os que era 0 viram 1, 1 vira 2 e assim por diante\n",
        "    principalDf['cluster'] = principalDf['cluster'] + 1\n",
        "\n",
        "    # Plota o gráfico de dispersão usando o matplotlib\n",
        "    fig = px.scatter(principalDf, x='principal component 1', y='principal component 2', symbol='cluster', size='cluster', color='cluster')\n",
        "    \n",
        "    # Atualiza o layout do gráfico\n",
        "    fig.update_layout(\n",
        "        width=800, \n",
        "        height=800)\n",
        "    \n",
        "    # Atualiza o X e Y do gráfico retirando-os\n",
        "    fig.update_xaxes(title_text='')\n",
        "    fig.update_yaxes(title_text='')\n",
        "    \n",
        "    # Remove a barra de cores\n",
        "    fig.update_layout(coloraxis_showscale=False)\n",
        "    \n",
        "    # Retira o fundo do gráfico (grid) colocando-o branco\n",
        "    fig.update_layout(plot_bgcolor='white')\n",
        "\n",
        "    # Retira o axis do gráfico\n",
        "    fig.update_xaxes(showline=False, showgrid=False, zeroline=False)   \n",
        "    fig.update_yaxes(showline=False, showgrid=False, zeroline=False)\n",
        "    \n",
        "    # Retira os numeros do eixo X e Y\n",
        "    fig.update_xaxes(showticklabels=False)\n",
        "    fig.update_yaxes(showticklabels=False)\n",
        "    \n",
        "    # Organiza a legenda em ordem crescente de clusters\n",
        "    fig.for_each_trace(lambda t: t.update(name='Cluster ' + str(t.name)))\n",
        "    \n",
        "    # Configura a legenda\n",
        "    fig.update_layout(\n",
        "        legend=dict(\n",
        "            traceorder='normal',\n",
        "            font=dict(\n",
        "                family='sans-serif',\n",
        "                size=20,\n",
        "                color='black'\n",
        "            ),\n",
        "            bordercolor='Black',\n",
        "            borderwidth=2\n",
        "        ),\n",
        "        \n",
        "        # Padding para tirar o espaço em branco em volta do gráfico\n",
        "        margin=dict(l=0, r=0, t=0, b=0)\n",
        "    )\n",
        "    \n",
        "    # Retira o titulo da legenda\n",
        "    fig.update_layout(legend_title_text='')\n",
        "    \n",
        "    # Exibe o gráfico\n",
        "    fig.show()\n",
        "    \n",
        "    # Calcula o coeficiente de silhueta\n",
        "    silhouette_agnes = silhouette_score(df, X)\n",
        "    \n",
        "    # Rand score do AGNES\n",
        "    rand_agnes = metrics.adjusted_rand_score(df['clusters'], X)\n",
        "    \n",
        "    # Homogeneidade\n",
        "    homogeneity = metrics.homogeneity_score(df['clusters'], X)\n",
        "    \n",
        "    # Completude\n",
        "    completeness = metrics.completeness_score(df['clusters'], X)\n",
        "    \n",
        "    # Matriz de confusão\n",
        "    confusion_matrix = metrics.cluster.contingency_matrix(df['clusters'], X)\n",
        "    \n",
        "    # Printa\n",
        "    console = Console()\n",
        "    table = Table(title=\"Resultados do AGNES\")\n",
        "    table.add_column(\"Silhouette Score\", style=\"cyan\", justify=\"center\")\n",
        "    table.add_column(\"Rand Score\", style=\"magenta\", justify=\"center\")\n",
        "    table.add_column(\"Homogeneidade\", style=\"green\", justify=\"center\")\n",
        "    table.add_column(\"Completude\", style=\"yellow\", justify=\"center\")\n",
        "    \n",
        "    table.add_row(str(silhouette_agnes), str(rand_agnes), str(homogeneity), str(completeness))\n",
        "    \n",
        "    console.print(table)\n",
        "    \n",
        "    # Printa a matriz de confusão\n",
        "    print(\"Matriz de Confusão\")\n",
        "    print(confusion_matrix)\n",
        "    \n",
        "    return silhouette_agnes\n",
        "    \n",
        "# Chamada da função AGNES\n",
        "silhouette_agnes = AGNES_Trainer(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Técnicas extras\n",
        "\n",
        "## O que são?\n",
        "\n",
        "Tanto o t-SNE (t-Distributed Stochastic Neighbor Embedding) quanto o UMAP (Uniform Manifold Approximation and Projection) são técnicas de redução de dimensionalidade que são comumente usadas para visualização de dados de alta dimensão. Ambos seguem um processo semelhante onde começam calculando probabilidades de alta dimensão p, depois probabilidades de baixa dimensão q, seguido pelo cálculo da função de custo C(p,q) comparando as diferenças entre as probabilidade\n",
        "\n",
        "No entanto, existem algumas diferenças importantes entre os dois:\n",
        "\n",
        "- Velocidade e Escalabilidade: O UMAP geralmente é mais rápido que o t-SNE e pode lidar melhor com conjuntos de dados maiores.\n",
        "- Preservação da Estrutura Global: Enquanto o t-SNE se concentra em preservar a estrutura local dos dados (ou seja, mantém pontos que são próximos no espaço de alta dimensão próximos no espaço de baixa dimensão), o UMAP tenta preservar tanto a estrutura local quanto a global dos dados. Isso significa que o UMAP pode preservar melhor as relações de distância entre os clusters.\n",
        "- Reprodutibilidade: O t-SNE é uma técnica estocástica, o que significa que você pode obter resultados ligeiramente diferentes cada vez que você executar o código, mesmo com a mesma semente aleatória. Por outro lado, o UMAP é mais consistente e produz resultados mais reprodutíveis.\n",
        "- Uso de Hiperparâmetros: Ambos os métodos têm hiperparâmetros que podem ser ajustados para alterar o resultado da redução de dimensionalidade. No entanto, a interpretação e o ajuste desses hiperparâmetros podem ser menos intuitivos no t-SNE do que no UMAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def TSNE_trainer(df):\n",
        "    \n",
        "    # Define o modelo\n",
        "    model = TSNE(n_components=2, random_state=0)\n",
        "    \n",
        "    # Define os dados de treino\n",
        "    X = model.fit_transform(df)\n",
        "    \n",
        "    # Plota o gráfico de dispersão dos dados TSNE\n",
        "    \n",
        "    # Cria um dataframe com os componentes principais\n",
        "    principalDf = pd.DataFrame(data = X, columns = ['TSNE 1', 'TSNE 2'])\n",
        "\n",
        "    # Plota o gráfico de dispersão\n",
        "    fig = px.scatter(principalDf, x='TSNE 1', y='TSNE 2')\n",
        "\n",
        "    # Atualiza o layout do gráfico\n",
        "    fig.update_layout(\n",
        "        width=800, \n",
        "        height=800)\n",
        "\n",
        "    # Atualiza o X e Y do gráfico\n",
        "    fig.update_xaxes(title_text='TSNE 1')\n",
        "    fig.update_yaxes(title_text='TSNE 2')\n",
        "    \n",
        "    # Exibe o gráfico\n",
        "    fig.show()\n",
        "    \n",
        "# Chamada da função TSNE\n",
        "TSNE_trainer(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "\n",
        "def UMAP_trainer(df):\n",
        "    \n",
        "    # Define o modelo\n",
        "    model = UMAP(n_components=2, random_state=0)\n",
        "    \n",
        "    # Define os dados de treino\n",
        "    X = model.fit_transform(df)\n",
        "    \n",
        "    # Plota o gráfico de dispersão dos dados UMAP\n",
        "    \n",
        "    # Cria um dataframe com os componentes principais\n",
        "    principalDf = pd.DataFrame(data = X, columns = ['UMAP 1', 'UMAP 2'])\n",
        "\n",
        "    # Plota o gráfico de dispersão\n",
        "    fig = px.scatter(principalDf, x='UMAP 1', y='UMAP 2')\n",
        "\n",
        "    # Atualiza o layout do gráfico\n",
        "    fig.update_layout(\n",
        "        width=800, \n",
        "        height=800)\n",
        "\n",
        "    # Atualiza o X e Y do gráfico\n",
        "    fig.update_xaxes(title_text='UMAP 1')\n",
        "    fig.update_yaxes(title_text='UMAP 2')\n",
        "    \n",
        "    # Exibe o gráfico\n",
        "    fig.show()\n",
        "    \n",
        "# Chamada da função UMAP\n",
        "UMAP_trainer(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
